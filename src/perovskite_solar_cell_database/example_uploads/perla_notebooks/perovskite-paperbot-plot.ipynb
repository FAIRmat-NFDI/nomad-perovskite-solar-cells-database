{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3410473f",
   "metadata": {
    "id": "3410473f"
   },
   "outputs": [],
   "source": [
    "# ruff: noqa: E402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c5ff83-5a48-42e4-b32f-9c4aa1bf4d58",
   "metadata": {
    "id": "69c5ff83-5a48-42e4-b32f-9c4aa1bf4d58"
   },
   "source": [
    "<div style=\"\n",
    "    background-color: #f7f7f7;\n",
    "    background-image: url('data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+CjxzdmcKICAgd2lkdGg9IjcyIgogICBoZWlnaHQ9IjczIgogICB2aWV3Qm94PSIwIDAgNzIgNzMiCiAgIGZpbGw9Im5vbmUiCiAgIHZlcnNpb249IjEuMSIKICAgaWQ9InN2ZzEzMTkiCiAgIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIKICAgeG1sbnM6c3ZnPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CiAgPGRlZnMKICAgICBpZD0iZGVmczEzMjMiIC8+CiAgPHBhdGgKICAgICBkPSJNIC0wLjQ5OTk4NSwxNDUgQyAzOS41MzMsMTQ1IDcyLDExMi41MzIgNzIsNzIuNSA3MiwzMi40Njc4IDM5LjUzMywwIC0wLjQ5OTk4NSwwIC00MC41MzI5LDAgLTczLDMyLjQ2NzggLTczLDcyLjUgYyAwLDQwLjAzMiAzMi40NjcxLDcyLjUgNzIuNTAwMDE1LDcyLjUgeiIKICAgICBmaWxsPSIjMDA4YTY3IgogICAgIGZpbGwtb3BhY2l0eT0iMC4yNSIKICAgICBpZD0icGF0aDEzMTciIC8+Cjwvc3ZnPgo='), url('data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+CjxzdmcKICAgd2lkdGg9IjIxNyIKICAgaGVpZ2h0PSIyMjMiCiAgIHZpZXdCb3g9IjAgMCAyMTcgMjIzIgogICBmaWxsPSJub25lIgogICB2ZXJzaW9uPSIxLjEiCiAgIGlkPSJzdmcxMTA3IgogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciCiAgIHhtbG5zOnN2Zz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxkZWZzCiAgICAgaWQ9ImRlZnMxMTExIiAvPgogIDxwYXRoCiAgICAgZD0ibSAyMi4wNDIsNDUuMDEwOSBjIDIxLjM2MjUsMjEuMjc1NyA1NS45NzYsMjEuMjc1NyA3Ny41MTkyLDAgQyAxMTkuNTU4LDI1LjA4IDE1MS41MDIsMjMuNzM1MiAxNzIuODY0LDQxLjM3OCBjIDEuMzQ1LDEuNTI1NCAyLjY5LDMuMjUxNiA0LjIzNiw0Ljc5NzEgMjEuMzYzLDIxLjI3NTYgMjEuMzYzLDU1Ljc5ODkgMCw3Ny4yNTQ5IC0yMS4zNjIsMjEuMjc2IC0yMS4zNjIsNTUuNzk4IDAsNzcuMjU1IDIxLjM2MywyMS40NTYgNTUuOTc2LDIxLjI3NSA3Ny41MiwwIDIxLjU0MywtMjEuMjc2IDIxLjM2MiwtNTUuNzk5IDAsLTc3LjI1NSAtMjEuMzYzLC0yMS4yNzYgLTIxLjM2MywtNTUuNzk4NiAwLC03Ny4yNTQ5IDEyLjY4OSwtMTIuNjQ1IDE3Ljg4OSwtMzAuMTA3MSAxNS4zOTksLTQ2LjU4NTc2IC0xLjU0NiwtMTEuNTAwOTQgLTYuNzI2LC0yMi44MjExNCAtMTUuNTgsLTMxLjYzMjU0IC0yMS4zNjMsLTIxLjI3NTYgLTU1Ljk3NiwtMjEuMjc1NiAtNzcuNTE5LDAgLTIxLjM2MywyMS4yNzU3IC01NS45NzYsMjEuMjc1NyAtNzcuNTE5NCwwIC0yMS4zNjI1LC0yMS4yNzU2IC01NS45NzYxLC0yMS4yNzU2IC03Ny41MTkyLDAgQyAwLjY3OTU2NSwtMTAuNzg3NiAwLjY3OTU5NiwyMy43MzUyIDIyLjA0Miw0NS4wMTA5IFoiCiAgICAgZmlsbD0iIzJhNGNkZiIKICAgICBzdHJva2U9IiMyYTRjZGYiCiAgICAgc3Ryb2tlLXdpZHRoPSIxMiIKICAgICBzdHJva2UtbWl0ZXJsaW1pdD0iMTAiCiAgICAgaWQ9InBhdGgxMTA1IiAvPgogIDxwYXRoCiAgICAgZD0ibSA1MS45OTUyMTIsMjIyLjczMDEzIGMgMjguMzU5MSwwIDUxLjM1ODM5OCwtMjIuOTk5OSA1MS4zNTgzOTgsLTUxLjM1ODQgMCwtMjguMzU4NiAtMjIuOTk5Mjk4LC01MS4zNTg1OSAtNTEuMzU4Mzk4LC01MS4zNTg1OSAtMjguMzU5MSwwIC01MS4zNTg2MDIsMjIuOTk5OTkgLTUxLjM1ODYwMiw1MS4zNTg1OSAwLDI4LjM1ODUgMjIuOTk5NTAyLDUxLjM1ODQgNTEuMzU4NjAyLDUxLjM1ODQgeiIKICAgICBmaWxsPSIjMTkyZTg2IgogICAgIGZpbGwtb3BhY2l0eT0iMC4zNSIKICAgICBpZD0icGF0aDE5MzciIC8+Cjwvc3ZnPgo=') ;\n",
    "    background-position: left bottom, right top;\n",
    "    background-repeat: no-repeat,  no-repeat;\n",
    "    background-size: auto 60px, auto 160px;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 0px 3px 1px -2px rgba(0, 0, 0, 0.2), 0px 2px 2px 0px rgba(0, 0, 0, 0.14), 0px 1px 5px 0px rgba(0,0,0,.12);\">\n",
    "\n",
    "<h1 style=\"\n",
    "    color: #2a4cdf;\n",
    "    font-style: normal;\n",
    "    font-size: 2.25rem;\n",
    "    line-height: 1.4em;\n",
    "    font-weight: 600;\n",
    "    padding: 30px 200px 0px 30px;\">\n",
    "        Perovskite Papersbot Analysis</h1>\n",
    "\n",
    "<p style=\"\n",
    "    line-height: 1.4em;\n",
    "    padding: 30px 200px 0px 30px;\">\n",
    "    This notebook retrieves data from the Perovskite Papersbot and plots the filtering steps.\n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 1.25em; font-style: italic; padding: 5px 200px 30px 30px;\">\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327abb1-7fef-4432-85c2-abcaf71b9fb2",
   "metadata": {
    "id": "c327abb1-7fef-4432-85c2-abcaf71b9fb2"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from plotly_theme import register_template, set_defaults  # type: ignore\n",
    "\n",
    "# Register and set default Plotly theme for consistent styling\n",
    "register_template()\n",
    "set_defaults()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323aed1e",
   "metadata": {
    "id": "323aed1e"
   },
   "source": [
    "### Overview\n",
    "\n",
    "1.  **Data Retrieval**: Downloads Perovskite Papersbot run log files stored in Hugging Face repo [`pilar12/perovskite-papersbot`](https://huggingface.co/datasets/pilar12/perovskite-papersbot/tree/comb_regex).\n",
    "2.  **Data Processing**: Loads and processes the downloaded CSV files to extract statistics related to paper matching, abstract availability, and open-access status.\n",
    "3.  **Visualisation**: Generates a Sankey diagram to visually represent the multi-stage filtering pipeline for identifying new perovskite solar cell papers, showing the flow of papers through different stages of filtering.\n",
    "4.  **Summary**: Provides a textual summary of the filtering process, including the total number of papers parsed, initial matches, papers filtered out, and the final count of relevant and open-access papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HAI4rcWjHpkD",
   "metadata": {
    "id": "HAI4rcWjHpkD"
   },
   "source": [
    "#### 1. Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c966d29-e2bd-4c21-aa1e-6015796ceb20",
   "metadata": {
    "id": "5c966d29-e2bd-4c21-aa1e-6015796ceb20"
   },
   "outputs": [],
   "source": [
    "# Initialize Hugging Face API token and repository ID\n",
    "repo_id = 'pilar12/perovskite-papersbot'\n",
    "api = HfApi()\n",
    "local_dir = 'paperbot_runs'\n",
    "\n",
    "\n",
    "# Function to download files from the Hugging Face repository\n",
    "def download_files():\n",
    "    snapshot_path = snapshot_download(\n",
    "        repo_id=repo_id,\n",
    "        local_dir=local_dir,  # Local directory to save the downloaded files\n",
    "        repo_type='dataset',\n",
    "        revision='comb_regex',\n",
    "        force_download=True,\n",
    "    )\n",
    "    return snapshot_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639926e6-e77c-4c88-86f1-7fb2d07b4a00",
   "metadata": {
    "id": "639926e6-e77c-4c88-86f1-7fb2d07b4a00"
   },
   "outputs": [],
   "source": [
    "download_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbae33f-bbbe-455c-ae0b-7cade15f67bb",
   "metadata": {
    "id": "Wqt480GQH8fJ"
   },
   "source": [
    "#### 2. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea8366-e8c4-4565-86f3-ee43b94d61fb",
   "metadata": {
    "id": "3eea8366-e8c4-4565-86f3-ee43b94d61fb"
   },
   "outputs": [],
   "source": [
    "def get_stats():\n",
    "    # Load post-processed data and full entry statistics\n",
    "    post_proc_df = pd.read_csv(f'{local_dir}/post_proc.csv').replace({float('nan'): ''})\n",
    "    post_proc_df['pdf_available'] = post_proc_df['pdf_available'].apply(\n",
    "        lambda x: False if x == '' else x\n",
    "    )\n",
    "    full_df = pd.read_csv(f'{local_dir}/entry_stats.csv').replace({float('nan'): ''})\n",
    "\n",
    "    # Filter data based on different matching criteria\n",
    "    full_rss = full_df[full_df['match'] == 1]\n",
    "    full_strict_rss = full_df[full_df['strict_regex'] > 2]\n",
    "    strict_rss_with_doi = post_proc_df[post_proc_df['strict_regex'] > 2]\n",
    "    full_relaxed_rss = full_df[(full_df['match'] == 1) & (full_df['strict_regex'] <= 2)]\n",
    "    relaxed_rss_with_doi = post_proc_df[\n",
    "        (post_proc_df['match'] == 1) & (post_proc_df['strict_regex'] <= 2)\n",
    "    ]\n",
    "\n",
    "    # Store dataframes in a dictionary for easier access\n",
    "    dfs = {\n",
    "        'full': (full_rss, post_proc_df),\n",
    "        'strict_rss': (full_strict_rss, strict_rss_with_doi),\n",
    "        'relaxed_rss': (full_relaxed_rss, relaxed_rss_with_doi),\n",
    "    }\n",
    "\n",
    "    # Initialize statistics dictionary\n",
    "    match_df = post_proc_df[\n",
    "        (post_proc_df['abstract_match']) & (post_proc_df['doi_good_to_go'])\n",
    "    ]\n",
    "    stats = {\n",
    "        'total': len(full_df),\n",
    "        'oa': len(match_df[match_df['pdf_available']]),\n",
    "        'non_oa': len(\n",
    "            match_df[match_df['pdf_url'] == '']\n",
    "        ),  # Non-OA with abstract match\n",
    "        'oa_no_info': len(match_df[match_df['pdf_url'].apply(lambda x: 'Error' in x)]),\n",
    "    }  # OA with errors in URL\n",
    "\n",
    "    # Calculate statistics for each category (full, strict_rss, relaxed_rss)\n",
    "    for key, (fdf, doi_df) in dfs.items():\n",
    "        abs_df = doi_df[doi_df['abstract_found']]\n",
    "        stats[f'{key}_match'] = len(fdf)\n",
    "        stats[f'{key}_match_with_doi'] = len(doi_df)\n",
    "        stats[f'{key}_match_missing_doi'] = len(fdf) - len(doi_df)\n",
    "        stats[f'{key}_abstracts_found'] = len(abs_df)\n",
    "        stats[f'{key}_missing_abstracts'] = len(doi_df) - len(abs_df)\n",
    "        stats[f'{key}_strict_matches_with_abstract_found'] = len(\n",
    "            abs_df[abs_df['abstract_match']]\n",
    "        )\n",
    "        stats[f'{key}_strict_matches_without_abstract'] = len(\n",
    "            doi_df[doi_df['abstract_match']]\n",
    "        ) - len(abs_df[abs_df['abstract_match']])\n",
    "        stats[f'{key}_total_strict_matches'] = len(doi_df[doi_df['abstract_match']])\n",
    "        stats[f'{key}_doi_good_matches_with_abstract_found'] = len(\n",
    "            abs_df[(abs_df['abstract_match']) & (abs_df['doi_good_to_go'])]\n",
    "        )\n",
    "        stats[f'{key}_doi_good_matches_without_abstract'] = len(\n",
    "            doi_df[(doi_df['abstract_match']) & (doi_df['doi_good_to_go'])]\n",
    "        ) - len(abs_df[(abs_df['abstract_match']) & (abs_df['doi_good_to_go'])])\n",
    "        stats[f'{key}_total_doi_good_matches'] = len(\n",
    "            doi_df[(doi_df['abstract_match']) & (doi_df['doi_good_to_go'])]\n",
    "        )\n",
    "\n",
    "    # Ensure all stats are integers\n",
    "    stats = {k: int(v) for k, v in stats.items()}\n",
    "\n",
    "    # Get the time range of parsed data\n",
    "    parsed_times = full_df['parsed_time'].values\n",
    "    start = min(parsed_times)\n",
    "    end = max(parsed_times)\n",
    "    stats['period'] = end - start\n",
    "    stats['start'] = time.strftime('%d-%m-%Y', time.gmtime(start))\n",
    "    stats['end'] = time.strftime('%d-%m-%Y', time.gmtime(end))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5McLViCHIEy5",
   "metadata": {
    "id": "5McLViCHIEy5"
   },
   "source": [
    "#### 3. Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2867bc5d-8c02-408a-aeea-99f97a30048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_sankey():\n",
    "    # Get statistics from the data\n",
    "    stats = get_stats()\n",
    "\n",
    "    # Define labels for the Sankey diagram nodes\n",
    "    labels = [\n",
    "        'RSS Summary <br>Keyword Match',\n",
    "        'Un-Resolvable Reference',\n",
    "        'Abstract Found',\n",
    "        'Abstract Missing',\n",
    "        'Filtered Papers',\n",
    "        'Open-Access',\n",
    "        'Non Open-Access',\n",
    "        'Failed Retrieval',\n",
    "    ]\n",
    "\n",
    "    # Define source and target nodes for the links\n",
    "    sources = [0, 0, 0, 2, 3, 4, 4, 4]\n",
    "    targets = [1, 2, 3, 4, 4, 5, 6, 7]\n",
    "\n",
    "    # Define the values (thickness) for the links based on calculated statistics\n",
    "    values = [\n",
    "        stats['full_match_missing_doi'],  # Un-Resolvable Reference\n",
    "        stats['full_abstracts_found'],  # Abstract Found\n",
    "        stats['full_missing_abstracts'],  # Abstract Missing\n",
    "        stats['full_doi_good_matches_with_abstract_found'],  # Keyword Match,\n",
    "        stats['full_doi_good_matches_without_abstract'],  # Keyword Match\n",
    "        stats['oa'],  # Open-Access\n",
    "        stats['non_oa'],  # Non Open-Acess\n",
    "        stats['oa_no_info'],  # Failed Retrieval\n",
    "    ]\n",
    "\n",
    "    # Calculate the total value for each node to display in the label\n",
    "    node_values = []\n",
    "    for i in range(len(labels)):\n",
    "        v = 0\n",
    "        node_list = targets\n",
    "        if i not in targets:\n",
    "            node_list = sources\n",
    "        for j in range(len(node_list)):\n",
    "            v += values[j] if node_list[j] == i else 0\n",
    "        node_values.append(v)\n",
    "\n",
    "    # Format labels to include node values\n",
    "    labels = [f'<b>{i}<br>{v}</b>' for i, v in zip(labels, node_values)]\n",
    "\n",
    "    # Create the Sankey diagram figure\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Sankey(\n",
    "                valueformat='.0f',\n",
    "                arrangement='snap',\n",
    "                node=dict(\n",
    "                    pad=8,\n",
    "                    thickness=10,\n",
    "                    line=dict(color='black', width=0.5),\n",
    "                    label=labels,\n",
    "                    align='left',\n",
    "                ),\n",
    "                link=dict(\n",
    "                    source=sources,\n",
    "                    target=targets,\n",
    "                    value=values,\n",
    "                    color='rgba(0,0,255,0.2)',\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Set a title for the plot including total papers and date range\n",
    "    fig.update_layout(\n",
    "        title_text=f'<b>{stats[\"total\"]} papers parsed  from {stats[\"start\"]} to {stats[\"end\"]}</b>',\n",
    "        font_size=12,\n",
    "        width=600,\n",
    "    )\n",
    "\n",
    "    # Display the plot\n",
    "    fig.show()\n",
    "    return fig, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da47ce-2988-45bc-bba3-3972b56dc6b1",
   "metadata": {
    "id": "67da47ce-2988-45bc-bba3-3972b56dc6b1"
   },
   "outputs": [],
   "source": [
    "fig, stats = complex_sankey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ctLEqRaIOX0",
   "metadata": {
    "id": "6ctLEqRaIOX0"
   },
   "source": [
    "#### 4. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bab0a2e-a1da-4c9f-8f24-c66b029742cf",
   "metadata": {
    "id": "0bab0a2e-a1da-4c9f-8f24-c66b029742cf"
   },
   "outputs": [],
   "source": [
    "f'The multi-stage filtering pipeline for identifying new perovskite solar cell papers. \\\n",
    "Over a {int(stats[\"period\"] / 86400)}-day period ({stats[\"start\"]} to {stats[\"end\"]}), {stats[\"total\"]} papers were parsed from Journal RSS feeds. \\\n",
    "An initial match against RSS summaries identified {stats[\"full_match\"]} candidates. Subsequent steps remove papers with unresolvable DOIs (n = {stats[\"full_match_missing_doi\"]}),\\\n",
    "and failing a secondary strict match (n = {stats[\"full_match\"] - stats[\"full_total_strict_matches\"] - stats[\"full_match_missing_doi\"]}). \\\n",
    "Further filtering is done to exclude theoretical, computational and review works (n = {stats[\"full_total_strict_matches\"] - stats[\"full_total_doi_good_matches\"]}), yielding a final set of {stats[\"full_total_doi_good_matches\"]} relevant papers of which {stats[\"oa\"]} were open-access papers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5MGXJr48IXjA",
   "metadata": {
    "id": "5MGXJr48IXjA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
